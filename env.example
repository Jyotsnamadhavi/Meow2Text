# LLM Configuration
LLM_PROVIDER=local  # "openai" or "local"

# OpenAI API Key (only needed if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here

# Local LLM Configuration (only needed if LLM_PROVIDER=local)
LOCAL_MODEL=llama2:7b
LOCAL_TEMPERATURE=0.8
LOCAL_MAX_TOKENS=150

# Server Configuration
HOST=0.0.0.0
PORT=3001

# CORS Settings
ALLOWED_ORIGINS=http://localhost:3002,http://127.0.0.1:3002 